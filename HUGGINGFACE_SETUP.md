# ü§ó D√©ploiement du Mod√®le sur Hugging Face Hub

Ce guide explique comment h√©berger votre mod√®le ESI sur Hugging Face Hub pour un d√©ploiement gratuit sur Streamlit Cloud.

## üìã Pourquoi Hugging Face Hub?

- ‚úÖ **Gratuit et illimit√©** pour les mod√®les publics
- ‚úÖ **Pas de limite de taille** (contrairement √† Git: 1GB)
- ‚úÖ **T√©l√©chargement automatique** au d√©marrage de l'app
- ‚úÖ **Versioning int√©gr√©** du mod√®le
- ‚úÖ **CDN mondial** pour chargement rapide

## üöÄ √âtapes d'Upload (D√©j√† effectu√©es)

### 1. Authentification
```bash
pip install huggingface_hub
python login_hf.py
```

### 2. Upload du Mod√®le
```bash
python upload_to_huggingface.py
```

Le script a upload√© le mod√®le vers: **https://huggingface.co/yallou/esi-clinical-triage**

## ‚öôÔ∏è Configuration de l'Application

### Option 1: Variable d'Environnement (Recommand√© pour Production)

Sur Streamlit Cloud, ajoutez dans les **Secrets**:
```toml
# .streamlit/secrets.toml (sur Streamlit Cloud)
HF_MODEL_NAME = "yallou/esi-clinical-triage"
```

### Option 2: Variable d'Environnement Locale

Pour tester localement:
```bash
# Windows
set HF_MODEL_NAME=yallou/esi-clinical-triage
streamlit run app.py

# Linux/Mac
export HF_MODEL_NAME=yallou/esi-clinical-triage
streamlit run app.py
```

### Option 3: Fallback Local (D√©veloppement)

Si `HF_MODEL_NAME` n'est pas d√©fini, l'app cherchera le mod√®le dans `model/final_model/` (local).

## üì¶ Flux de Chargement du Mod√®le

```python
# app.py - Fonction charger_modele()

1. V√©rifie si HF_MODEL_NAME est d√©fini
   ‚îú‚îÄ OUI ‚Üí T√©l√©charge depuis Hugging Face (production)
   ‚îî‚îÄ NON ‚Üí Cherche model/final_model/ (d√©veloppement)
                ‚îú‚îÄ Existe ‚Üí Charge le mod√®le local
                ‚îî‚îÄ N'existe pas ‚Üí Charge ClinicalBERT de base (fallback)
```

## üåê D√©ploiement sur Streamlit Cloud

### 1. Pousser le Code sur GitHub

```bash
# Ajouter tous les fichiers (sans le mod√®le local gr√¢ce au .gitignore)
git add .
git commit -m "Add Hugging Face model integration"
git push origin main
```

**Important**: Le dossier `model/` (4GB) est maintenant ignor√© dans `.gitignore`, donc ne sera PAS pouss√© sur GitHub.

### 2. Configurer Streamlit Cloud

1. Allez sur [https://share.streamlit.io/](https://share.streamlit.io/)
2. Connectez votre repository GitHub
3. Dans **Advanced settings > Secrets**, ajoutez:

```toml
HF_MODEL_NAME = "yallou/esi-clinical-triage"
```

4. D√©ployez!

### 3. Premier D√©marrage

Au premier d√©marrage, Streamlit Cloud va:
- ‚úÖ Installer les d√©pendances (`requirements.txt`)
- ‚úÖ T√©l√©charger le mod√®le depuis Hugging Face (~433MB)
- ‚úÖ Mettre en cache le mod√®le (`@st.cache_resource`)

**Temps estim√©**: 2-3 minutes pour le premier d√©marrage, puis instantan√© gr√¢ce au cache.

## üìä Avantages de cette Architecture

| Aspect | Avant (Git) | Apr√®s (Hugging Face) |
|--------|-------------|----------------------|
| **Taille repo** | 8.3GB ‚ùå | ~50MB ‚úÖ |
| **Limite Streamlit** | D√©passe 1GB ‚ùå | Sous 1GB ‚úÖ |
| **Temps upload** | Tr√®s long | Rapide |
| **Versioning mod√®le** | Difficile | Natif HF ‚úÖ |
| **Partage mod√®le** | Impossible | Public HF ‚úÖ |

## üîÑ Mise √† Jour du Mod√®le

Pour mettre √† jour le mod√®le apr√®s un nouvel entra√Ænement:

```bash
# 1. R√©entra√Æner le mod√®le (train.py)
python train.py

# 2. Re-uploader vers Hugging Face
python upload_to_huggingface.py

# 3. Red√©marrer l'app Streamlit
# Le cache se rafra√Æchira automatiquement
```

## üîí Mod√®le Priv√© (Optionnel)

Si vous voulez garder le mod√®le priv√©:

### 1. Modifier le Repository en Priv√©
Sur Hugging Face ‚Üí Settings ‚Üí Make Private

### 2. Cr√©er un Token Read
[https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) ‚Üí New Token ‚Üí Type: **Read**

### 3. Ajouter le Token dans Streamlit Secrets
```toml
# .streamlit/secrets.toml
HF_MODEL_NAME = "yallou/esi-clinical-triage"
HF_TOKEN = "hf_xxxxxxxxxxxxx"
```

### 4. Modifier app.py
```python
# Dans la fonction charger_modele()
HF_TOKEN = os.getenv("HF_TOKEN", None)

model = AutoModelForSequenceClassification.from_pretrained(
    HF_MODEL_NAME,
    use_auth_token=HF_TOKEN  # ‚Üê Ajouter cette ligne
)
```

## üìö Ressources

- **Mod√®le Hugging Face**: https://huggingface.co/yallou/esi-clinical-triage
- **Documentation HF Hub**: https://huggingface.co/docs/hub/index
- **Streamlit Cloud Docs**: https://docs.streamlit.io/streamlit-community-cloud

## üÜò D√©pannage

### Erreur: "Model not found"
- V√©rifiez que `HF_MODEL_NAME` est correctement d√©fini
- V√©rifiez que le mod√®le existe sur Hugging Face
- V√©rifiez votre connexion internet

### Erreur: "Token expired"
- Re-g√©n√©rez un token sur Hugging Face
- Re-connectez-vous avec `python login_hf.py`

### L'app est lente au d√©marrage
- Normal au premier lancement (t√©l√©charge le mod√®le)
- Les lancements suivants sont rapides gr√¢ce au cache

---

‚úÖ **Votre mod√®le est maintenant h√©berg√© sur Hugging Face!**
‚úÖ **Pr√™t pour un d√©ploiement gratuit sur Streamlit Cloud!**
